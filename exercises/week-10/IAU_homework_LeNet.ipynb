{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset\n",
    "\n",
    "<div style=\"display:flex;gap:2rem;\">\n",
    "<div style=\"flex:0.5;\">\n",
    "\n",
    "The MNIST dataset contains handwritten digit images and their labels. The images are 28x28 grayscale pixels.\n",
    "Normalization is applied so that pixel values are in the range [0, 1].\n",
    "\n",
    "Important Terms:\n",
    "- DNN (Deep Neural Network): A feed-forward neural network with multiple layers. In our example, we flatten the image and use dense layers.\n",
    "  Activation: relu function (f(x)=max(0,x)); dropout is used for regularization to prevent overfitting by randomly setting a fraction of inputs to 0.\n",
    "- CNN (Convolutional Neural Network): A neural network that uses convolutional layers to automatically extract spatial features.\n",
    "  Convolution formula (discrete): (f * g)[i, j] = ∑ₖ∑ₗ f[k, l] · g[i - k, j - l].\n",
    "  LeNet-5 is a classical CNN architecture originally designed for digit recognition.\n",
    "\n",
    "</div>\n",
    "<div style=\"flex:0.5;\">\n",
    "\n",
    "![image.png](attachment:2e9bb22b-bd54-46bf-9b51-9dcec519f5ba.png)\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The following code loads and preprocesses the MNIST dataset."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# load mnist dataset and normalize images by dividing by 255.0\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "\n",
    "# expand dims to add channel dimension (for grayscale images).\n",
    "train_x = tf.expand_dims(train_x, 3)\n",
    "test_x = tf.expand_dims(test_x, 3)\n",
    "\n",
    "# use a subset of training data for validation\n",
    "val_x = train_x[:5000]\n",
    "val_y = train_y[:5000]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Image Visualization\n",
    "\n",
    "We plot a few examples from the training set to visualize the handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# image visualization: plot a 5x5 grid of sample images\n",
    "n = 5\n",
    "fig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(12, 12))\n",
    "for i in range(n**2):\n",
    "    ax = axs[i // n, i % n]\n",
    "    # note: we adjust image values for proper display\n",
    "    ax.imshow((-train_x[i, :, :, 0] + 1) / 2, cmap=plt.cm.gray)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing with DNN\n",
    "\n",
    "A simple deep neural network (dnn) is defined for image classification.\n",
    "This dnn flattens the image and applies dense layers with relu activations and dropout."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_dnn = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_dnn.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# compile the dnn model with adam optimizer and sparse categorical cross-entropy loss\n",
    "model_dnn.compile(optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "# train the dnn model for 5 epochs\n",
    "model_dnn.fit(train_x, train_y, epochs=5)\n",
    "# evaluate the dnn model on test data\n",
    "model_dnn.evaluate(test_x, test_y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# predict on test data and display first prediction vs actual label\n",
    "pred_y = model_dnn.predict(test_x)\n",
    "display((pred_y[0], test_y[0]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# print predicted class and actual label for each test image\n",
    "for pred, actual in list(zip(pred_y, test_y)):\n",
    "    print(np.argmax(pred), actual)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing with CNN (LeNet)\n",
    "\n",
    "<div style=\"display:flex;gap:2rem;\">\n",
    "<div style=\"flex:0.5;\">\n",
    "\n",
    "> Based on https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/13_lenet-5.ipynb\n",
    "\n",
    "The following section implements a convolutional neural network based on the LeNet-5 architecture (1990).\n",
    "LeNet-5 uses convolutional layers with tanh activations, average pooling, and fully connected layers.\n",
    "Key concepts:\n",
    "- convolution: performs feature extraction using kernels (see formula above).\n",
    "- average pooling: reduces spatial dimensions by computing the average over windows.\n",
    "\n",
    "</div>\n",
    "<div style=\"flex:0.5;\">\n",
    "\n",
    "![image.png](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fd1d66cd11bf545ed8bca641334012a8b.png&f=1&nofb=1&ipt=a552f34c6975b62f1c334334839726eea965603c1815e6b982011b2dd60570bc&ipo=images)\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LeNet (1990) model"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lenet_5_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(120, activation='tanh'),\n",
    "    keras.layers.Dense(84, activation='tanh'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "lenet_5_model.summary()\n",
    "lenet_5_model.compile(optimizer='adam', loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluation\n",
    "\n",
    "We train the LeNet-5 model on the MNIST training data with a validation split.\n",
    "TensorBoard is used to log training details."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "lenet_5_model.fit(train_x, \n",
    "                  train_y, \n",
    "                  epochs=15, \n",
    "                  validation_data=(val_x, val_y), \n",
    "                  callbacks=[tensorboard_cb]\n",
    "                 )\n",
    "lenet_5_model.evaluate(test_x, test_y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful URLs\n",
    "\n",
    "TensorFlow - Python Deep Learning Neural Network API https://deeplizard.com/learn/video/RznKVRTFkBY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
