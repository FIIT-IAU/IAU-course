{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing in Python (continued)\n",
    "- [NLTK](http://www.nltk.org/book/)\n",
    "- gensim\n",
    "- word2vec\n",
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imported the `inaugural` corpus, now let's print all the files that are in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt',\n",
       " '2021-Biden.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get words(tokens) from `1789-Washington.txt` file in inaugural speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words('1789-Washington.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inaugural.words('1789-Washington.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the sentences from Washington's inaugural speech, immediately broken down into tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':'], ['Among', 'the', 'vicissitudes', 'incident', 'to', 'life', 'no', 'event', 'could', 'have', 'filled', 'me', 'with', 'greater', 'anxieties', 'than', 'that', 'of', 'which', 'the', 'notification', 'was', 'transmitted', 'by', 'your', 'order', ',', 'and', 'received', 'on', 'the', '14th', 'day', 'of', 'the', 'present', 'month', '.'], ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.sents('1789-Washington.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the corpus of inaugural speeches from different years into objects. Each object will contain data about a single inaugural speech: president`s name, year and text of the speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for fileid in inaugural.fileids():\n",
    "    year = fileid[:4]\n",
    "    name = fileid[5:].split('.')[0]\n",
    "    text = ' '.join(inaugural.words(fileid))\n",
    "    texts.append({'name': name, 'year': year, 'text': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Washington',\n",
       "  'year': '1789',\n",
       "  'text': 'Fellow - Citizens of the Senate and of the House of Representatives : Among the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was transmitted by your order , and received on the 14th day of the present month . On the one hand , I was summoned by my Country , whose voice I can never hear but with veneration and love , from a retreat which I had chosen with the fondest predilection , and , in my flattering hopes , with an immutable decision , as the asylum of my declining years -- a retreat which was rendered every day more necessary as well as more dear to me by the addition of habit to inclination , and of frequent interruptions in my health to the gradual waste committed on it by time . On the other hand , the magnitude and difficulty of the trust to which the voice of my country called me , being sufficient to awaken in the wisest and most experienced of her citizens a distrustful scrutiny into his qualifications , could not but overwhelm with despondence one who ( inheriting inferior endowments from nature and unpracticed in the duties of civil administration ) ought to be peculiarly conscious of his own deficiencies . In this conflict of emotions all I dare aver is that it has been my faithful study to collect my duty from a just appreciation of every circumstance by which it might be affected . All I dare hope is that if , in executing this task , I have been too much swayed by a grateful remembrance of former instances , or by an affectionate sensibility to this transcendent proof of the confidence of my fellow citizens , and have thence too little consulted my incapacity as well as disinclination for the weighty and untried cares before me , my error will be palliated by the motives which mislead me , and its consequences be judged by my country with some share of the partiality in which they originated . Such being the impressions under which I have , in obedience to the public summons , repaired to the present station , it would be peculiarly improper to omit in this first official act my fervent supplications to that Almighty Being who rules over the universe , who presides in the councils of nations , and whose providential aids can supply every human defect , that His benediction may consecrate to the liberties and happiness of the people of the United States a Government instituted by themselves for these essential purposes , and may enable every instrument employed in its administration to execute with success the functions allotted to his charge . In tendering this homage to the Great Author of every public and private good , I assure myself that it expresses your sentiments not less than my own , nor those of my fellow citizens at large less than either . No people can be bound to acknowledge and adore the Invisible Hand which conducts the affairs of men more than those of the United States . Every step by which they have advanced to the character of an independent nation seems to have been distinguished by some token of providential agency ; and in the important revolution just accomplished in the system of their united government the tranquil deliberations and voluntary consent of so many distinct communities from which the event has resulted can not be compared with the means by which most governments have been established without some return of pious gratitude , along with an humble anticipation of the future blessings which the past seem to presage . These reflections , arising out of the present crisis , have forced themselves too strongly on my mind to be suppressed . You will join with me , I trust , in thinking that there are none under the influence of which the proceedings of a new and free government can more auspiciously commence . By the article establishing the executive department it is made the duty of the President \" to recommend to your consideration such measures as he shall judge necessary and expedient .\" The circumstances under which I now meet you will acquit me from entering into that subject further than to refer to the great constitutional charter under which you are assembled , and which , in defining your powers , designates the objects to which your attention is to be given . It will be more consistent with those circumstances , and far more congenial with the feelings which actuate me , to substitute , in place of a recommendation of particular measures , the tribute that is due to the talents , the rectitude , and the patriotism which adorn the characters selected to devise and adopt them . In these honorable qualifications I behold the surest pledges that as on one side no local prejudices or attachments , no separate views nor party animosities , will misdirect the comprehensive and equal eye which ought to watch over this great assemblage of communities and interests , so , on another , that the foundation of our national policy will be laid in the pure and immutable principles of private morality , and the preeminence of free government be exemplified by all the attributes which can win the affections of its citizens and command the respect of the world . I dwell on this prospect with every satisfaction which an ardent love for my country can inspire , since there is no truth more thoroughly established than that there exists in the economy and course of nature an indissoluble union between virtue and happiness ; between duty and advantage ; between the genuine maxims of an honest and magnanimous policy and the solid rewards of public prosperity and felicity ; since we ought to be no less persuaded that the propitious smiles of Heaven can never be expected on a nation that disregards the eternal rules of order and right which Heaven itself has ordained ; and since the preservation of the sacred fire of liberty and the destiny of the republican model of government are justly considered , perhaps , as deeply , as finally , staked on the experiment entrusted to the hands of the American people . Besides the ordinary objects submitted to your care , it will remain with your judgment to decide how far an exercise of the occasional power delegated by the fifth article of the Constitution is rendered expedient at the present juncture by the nature of objections which have been urged against the system , or by the degree of inquietude which has given birth to them . Instead of undertaking particular recommendations on this subject , in which I could be guided by no lights derived from official opportunities , I shall again give way to my entire confidence in your discernment and pursuit of the public good ; for I assure myself that whilst you carefully avoid every alteration which might endanger the benefits of an united and effective government , or which ought to await the future lessons of experience , a reverence for the characteristic rights of freemen and a regard for the public harmony will sufficiently influence your deliberations on the question how far the former can be impregnably fortified or the latter be safely and advantageously promoted . To the foregoing observations I have one to add , which will be most properly addressed to the House of Representatives . It concerns myself , and will therefore be as brief as possible . When I was first honored with a call into the service of my country , then on the eve of an arduous struggle for its liberties , the light in which I contemplated my duty required that I should renounce every pecuniary compensation . From this resolution I have in no instance departed ; and being still under the impressions which produced it , I must decline as inapplicable to myself any share in the personal emoluments which may be indispensably included in a permanent provision for the executive department , and must accordingly pray that the pecuniary estimates for the station in which I am placed may during my continuance in it be limited to such actual expenditures as the public good may be thought to require . Having thus imparted to you my sentiments as they have been awakened by the occasion which brings us together , I shall take my present leave ; but not without resorting once more to the benign Parent of the Human Race in humble supplication that , since He has been pleased to favor the American people with opportunities for deliberating in perfect tranquillity , and dispositions for deciding with unparalleled unanimity on a form of government for the security of their union and the advancement of their happiness , so His divine blessing may be equally conspicuous in the enlarged views , the temperate consultations , and the wise measures on which the success of this Government must depend .'},\n",
       " {'name': 'Washington',\n",
       "  'year': '1793',\n",
       "  'text': 'Fellow citizens , I am again called upon by the voice of my country to execute the functions of its Chief Magistrate . When the occasion proper for it shall arrive , I shall endeavor to express the high sense I entertain of this distinguished honor , and of the confidence which has been reposed in me by the people of united America . Previous to the execution of any official act of the President the Constitution requires an oath of office . This oath I am now about to take , and in your presence : That if it shall be found during my administration of the Government I have in any instance violated willingly or knowingly the injunctions thereof , I may ( besides incurring constitutional punishment ) be subject to the upbraidings of all who are now witnesses of the present solemn ceremony .'},\n",
       " {'name': 'Adams',\n",
       "  'year': '1797',\n",
       "  'text': \"When it was first perceived , in early times , that no middle course for America remained between unlimited submission to a foreign legislature and a total independence of its claims , men of reflection were less apprehensive of danger from the formidable power of fleets and armies they must determine to resist than from those contests and dissensions which would certainly arise concerning the forms of government to be instituted over the whole and over the parts of this extensive country . Relying , however , on the purity of their intentions , the justice of their cause , and the integrity and intelligence of the people , under an overruling Providence which had so signally protected this country from the first , the representatives of this nation , then consisting of little more than half its present number , not only broke to pieces the chains which were forging and the rod of iron that was lifted up , but frankly cut asunder the ties which had bound them , and launched into an ocean of uncertainty . The zeal and ardor of the people during the Revolutionary war , supplying the place of government , commanded a degree of order sufficient at least for the temporary preservation of society . The Confederation which was early felt to be necessary was prepared from the models of the Batavian and Helvetic confederacies , the only examples which remain with any detail and precision in history , and certainly the only ones which the people at large had ever considered . But reflecting on the striking difference in so many particulars between this country and those where a courier may go from the seat of government to the frontier in a single day , it was then certainly foreseen by some who assisted in Congress at the formation of it that it could not be durable . Negligence of its regulations , inattention to its recommendations , if not disobedience to its authority , not only in individuals but in States , soon appeared with their melancholy consequences -- universal languor , jealousies and rivalries of States , decline of navigation and commerce , discouragement of necessary manufactures , universal fall in the value of lands and their produce , contempt of public and private faith , loss of consideration and credit with foreign nations , and at length in discontents , animosities , combinations , partial conventions , and insurrection , threatening some great national calamity . In this dangerous crisis the people of America were not abandoned by their usual good sense , presence of mind , resolution , or integrity . Measures were pursued to concert a plan to form a more perfect union , establish justice , insure domestic tranquillity , provide for the common defense , promote the general welfare , and secure the blessings of liberty . The public disquisitions , discussions , and deliberations issued in the present happy Constitution of Government . Employed in the service of my country abroad during the whole course of these transactions , I first saw the Constitution of the United States in a foreign country . Irritated by no literary altercation , animated by no public debate , heated by no party animosity , I read it with great satisfaction , as the result of good heads prompted by good hearts , as an experiment better adapted to the genius , character , situation , and relations of this nation and country than any which had ever been proposed or suggested . In its general principles and great outlines it was conformable to such a system of government as I had ever most esteemed , and in some States , my own native State in particular , had contributed to establish . Claiming a right of suffrage , in common with my fellow - citizens , in the adoption or rejection of a constitution which was to rule me and my posterity , as well as them and theirs , I did not hesitate to express my approbation of it on all occasions , in public and in private . It was not then , nor has been since , any objection to it in my mind that the Executive and Senate were not more permanent . Nor have I ever entertained a thought of promoting any alteration in it but such as the people themselves , in the course of their experience , should see and feel to be necessary or expedient , and by their representatives in Congress and the State legislatures , according to the Constitution itself , adopt and ordain . Returning to the bosom of my country after a painful separation from it for ten years , I had the honor to be elected to a station under the new order of things , and I have repeatedly laid myself under the most serious obligations to support the Constitution . The operation of it has equaled the most sanguine expectations of its friends , and from an habitual attention to it , satisfaction in its administration , and delight in its effects upon the peace , order , prosperity , and happiness of the nation I have acquired an habitual attachment to it and veneration for it . What other form of government , indeed , can so well deserve our esteem and love ? There may be little solidity in an ancient idea that congregations of men into cities and nations are the most pleasing objects in the sight of superior intelligences , but this is very certain , that to a benevolent human mind there can be no spectacle presented by any nation more pleasing , more noble , majestic , or august , than an assembly like that which has so often been seen in this and the other Chamber of Congress , of a Government in which the Executive authority , as well as that of all the branches of the Legislature , are exercised by citizens selected at regular periods by their neighbors to make and execute laws for the general good . Can anything essential , anything more than mere ornament and decoration , be added to this by robes and diamonds ? Can authority be more amiable and respectable when it descends from accidents or institutions established in remote antiquity than when it springs fresh from the hearts and judgments of an honest and enlightened people ? For it is the people only that are represented . It is their power and majesty that is reflected , and only for their good , in every legitimate government , under whatever form it may appear . The existence of such a government as ours for any length of time is a full proof of a general dissemination of knowledge and virtue throughout the whole body of the people . And what object or consideration more pleasing than this can be presented to the human mind ? If national pride is ever justifiable or excusable it is when it springs , not from power or riches , grandeur or glory , but from conviction of national innocence , information , and benevolence . In the midst of these pleasing ideas we should be unfaithful to ourselves if we should ever lose sight of the danger to our liberties if anything partial or extraneous should infect the purity of our free , fair , virtuous , and independent elections . If an election is to be determined by a majority of a single vote , and that can be procured by a party through artifice or corruption , the Government may be the choice of a party for its own ends , not of the nation for the national good . If that solitary suffrage can be obtained by foreign nations by flattery or menaces , by fraud or violence , by terror , intrigue , or venality , the Government may not be the choice of the American people , but of foreign nations . It may be foreign nations who govern us , and not we , the people , who govern ourselves ; and candid men will acknowledge that in such cases choice would have little advantage to boast of over lot or chance . Such is the amiable and interesting system of government ( and such are some of the abuses to which it may be exposed ) which the people of America have exhibited to the admiration and anxiety of the wise and virtuous of all nations for eight years under the administration of a citizen who , by a long course of great actions , regulated by prudence , justice , temperance , and fortitude , conducting a people inspired with the same virtues and animated with the same ardent patriotism and love of liberty to independence and peace , to increasing wealth and unexampled prosperity , has merited the gratitude of his fellow - citizens , commanded the highest praises of foreign nations , and secured immortal glory with posterity . In that retirement which is his voluntary choice may he long live to enjoy the delicious recollection of his services , the gratitude of mankind , the happy fruits of them to himself and the world , which are daily increasing , and that splendid prospect of the future fortunes of this country which is opening from year to year . His name may be still a rampart , and the knowledge that he lives a bulwark , against all open or secret enemies of his country ' s peace . This example has been recommended to the imitation of his successors by both Houses of Congress and by the voice of the legislatures and the people throughout the nation . On this subject it might become me better to be silent or to speak with diffidence ; but as something may be expected , the occasion , I hope , will be admitted as an apology if I venture to say that if a preference , upon principle , of a free republican government , formed upon long and serious reflection , after a diligent and impartial inquiry after truth ; if an attachment to the Constitution of the United States , and a conscientious determination to support it until it shall be altered by the judgments and wishes of the people , expressed in the mode prescribed in it ; if a respectful attention to the constitutions of the individual States and a constant caution and delicacy toward the State governments ; if an equal and impartial regard to the rights , interest , honor , and happiness of all the States in the Union , without preference or regard to a northern or southern , an eastern or western , position , their various political opinions on unessential points or their personal attachments ; if a love of virtuous men of all parties and denominations ; if a love of science and letters and a wish to patronize every rational effort to encourage schools , colleges , universities , academies , and every institution for propagating knowledge , virtue , and religion among all classes of the people , not only for their benign influence on the happiness of life in all its stages and classes , and of society in all its forms , but as the only means of preserving our Constitution from its natural enemies , the spirit of sophistry , the spirit of party , the spirit of intrigue , the profligacy of corruption , and the pestilence of foreign influence , which is the angel of destruction to elective governments ; if a love of equal laws , of justice , and humanity in the interior administration ; if an inclination to improve agriculture , commerce , and manufacturers for necessity , convenience , and defense ; if a spirit of equity and humanity toward the aboriginal nations of America , and a disposition to meliorate their condition by inclining them to be more friendly to us , and our citizens to be more friendly to them ; if an inflexible determination to maintain peace and inviolable faith with all nations , and that system of neutrality and impartiality among the belligerent powers of Europe which has been adopted by this Government and so solemnly sanctioned by both Houses of Congress and applauded by the legislatures of the States and the public opinion , until it shall be otherwise ordained by Congress ; if a personal esteem for the French nation , formed in a residence of seven years chiefly among them , and a sincere desire to preserve the friendship which has been so much for the honor and interest of both nations ; if , while the conscious honor and integrity of the people of America and the internal sentiment of their own power and energies must be preserved , an earnest endeavor to investigate every just cause and remove every colorable pretense of complaint ; if an intention to pursue by amicable negotiation a reparation for the injuries that have been committed on the commerce of our fellow - citizens by whatever nation , and if success can not be obtained , to lay the facts before the Legislature , that they may consider what further measures the honor and interest of the Government and its constituents demand ; if a resolution to do justice as far as may depend upon me , at all times and to all nations , and maintain peace , friendship , and benevolence with all the world ; if an unshaken confidence in the honor , spirit , and resources of the American people , on which I have so often hazarded my all and never been deceived ; if elevated ideas of the high destinies of this country and of my own duties toward it , founded on a knowledge of the moral principles and intellectual improvements of the people deeply engraven on my mind in early life , and not obscured but exalted by experience and age ; and , with humble reverence , I feel it to be my duty to add , if a veneration for the religion of a people who profess and call themselves Christians , and a fixed resolution to consider a decent respect for Christianity among the best recommendations for the public service , can enable me in any degree to comply with your wishes , it shall be my strenuous endeavor that this sagacious injunction of the two Houses shall not be without effect . With this great example before me , with the sense and spirit , the faith and honor , the duty and interest , of the same American people pledged to support the Constitution of the United States , I entertain no doubt of its continuance in all its energy , and my mind is prepared without hesitation to lay myself under the most solemn obligations to support it to the utmost of my power . And may that Being who is supreme over all , the Patron of Order , the Fountain of Justice , and the Protector in all ages of the world of virtuous liberty , continue His blessing upon this nation and its Government and give it all possible success and duration consistent with the ends of His providence .\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = texts[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the text, breaking it down into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have all the sentences of the first inaugural speech saved in the `sentences` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow - Citizens of the Senate and of the House of Representatives : Among the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was transmitted by your order , and received on the 14th day of the present month .',\n",
       " 'On the one hand , I was summoned by my Country , whose voice I can never hear but with veneration and love , from a retreat which I had chosen with the fondest predilection , and , in my flattering hopes , with an immutable decision , as the asylum of my declining years -- a retreat which was rendered every day more necessary as well as more dear to me by the addition of habit to inclination , and of frequent interruptions in my health to the gradual waste committed on it by time .',\n",
       " 'On the other hand , the magnitude and difficulty of the trust to which the voice of my country called me , being sufficient to awaken in the wisest and most experienced of her citizens a distrustful scrutiny into his qualifications , could not but overwhelm with despondence one who ( inheriting inferior endowments from nature and unpracticed in the duties of civil administration ) ought to be peculiarly conscious of his own deficiencies .',\n",
       " 'In this conflict of emotions all I dare aver is that it has been my faithful study to collect my duty from a just appreciation of every circumstance by which it might be affected .',\n",
       " 'All I dare hope is that if , in executing this task , I have been too much swayed by a grateful remembrance of former instances , or by an affectionate sensibility to this transcendent proof of the confidence of my fellow citizens , and have thence too little consulted my incapacity as well as disinclination for the weighty and untried cares before me , my error will be palliated by the motives which mislead me , and its consequences be judged by my country with some share of the partiality in which they originated .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same now, breaking down the first sentence into tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'House',\n",
       " 'of',\n",
       " 'Representatives',\n",
       " ':',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'vicissitudes',\n",
       " 'incident',\n",
       " 'to',\n",
       " 'life',\n",
       " 'no',\n",
       " 'event',\n",
       " 'could',\n",
       " 'have',\n",
       " 'filled',\n",
       " 'me',\n",
       " 'with',\n",
       " 'greater',\n",
       " 'anxieties',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'which',\n",
       " 'the',\n",
       " 'notification',\n",
       " 'was',\n",
       " 'transmitted',\n",
       " 'by',\n",
       " 'your',\n",
       " 'order',\n",
       " ',',\n",
       " 'and',\n",
       " 'received',\n",
       " 'on',\n",
       " 'the',\n",
       " '14th',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'present',\n",
       " 'month',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming returns the roots of words. Example in Slovak: *ryba -> ryb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fellow',\n",
       " '-',\n",
       " 'citizen',\n",
       " 'of',\n",
       " 'the',\n",
       " 'senat',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hous',\n",
       " 'of',\n",
       " 'repres',\n",
       " ':',\n",
       " 'among',\n",
       " 'the',\n",
       " 'vicissitud',\n",
       " 'incid',\n",
       " 'to',\n",
       " 'life',\n",
       " 'no',\n",
       " 'event',\n",
       " 'could',\n",
       " 'have',\n",
       " 'fill',\n",
       " 'me',\n",
       " 'with',\n",
       " 'greater',\n",
       " 'anxieti',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'which',\n",
       " 'the',\n",
       " 'notif',\n",
       " 'wa',\n",
       " 'transmit',\n",
       " 'by',\n",
       " 'your',\n",
       " 'order',\n",
       " ',',\n",
       " 'and',\n",
       " 'receiv',\n",
       " 'on',\n",
       " 'the',\n",
       " '14th',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'present',\n",
       " 'month',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "Lemmatization converts words to their basic dictionary form. Example in Slovk: *rybe -> ryba*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'House',\n",
       " 'of',\n",
       " 'Representatives',\n",
       " ':',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'vicissitude',\n",
       " 'incident',\n",
       " 'to',\n",
       " 'life',\n",
       " 'no',\n",
       " 'event',\n",
       " 'could',\n",
       " 'have',\n",
       " 'filled',\n",
       " 'me',\n",
       " 'with',\n",
       " 'greater',\n",
       " 'anxiety',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'which',\n",
       " 'the',\n",
       " 'notification',\n",
       " 'wa',\n",
       " 'transmitted',\n",
       " 'by',\n",
       " 'your',\n",
       " 'order',\n",
       " ',',\n",
       " 'and',\n",
       " 'received',\n",
       " 'on',\n",
       " 'the',\n",
       " '14th',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'present',\n",
       " 'month',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagging (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a grammatical category to each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fellow', 'NNP'),\n",
       " ('-', ':'),\n",
       " ('Citizens', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Senate', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('House', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Representatives', 'NNPS'),\n",
       " (':', ':'),\n",
       " ('Among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('vicissitudes', 'NNS'),\n",
       " ('incident', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('life', 'NN'),\n",
       " ('no', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('could', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('filled', 'VBN'),\n",
       " ('me', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('greater', 'JJR'),\n",
       " ('anxieties', 'NNS'),\n",
       " ('than', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('the', 'DT'),\n",
       " ('notification', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('transmitted', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('order', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('received', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('14th', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('present', 'JJ'),\n",
       " ('month', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition (NER) helps identify important entities like people, organizations, and locations in text. For this purpose we can use the ne_chunk function_ which processes POS-tagged words to extract this information. This improves text analysis for tasks like categorization and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a tree that shows the hierarchy of the detected entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [Tree('GPE', [('Fellow', 'NNP')]), ('-', ':'), ('Citizens', 'NNS'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Senate', 'NNP')]), ('and', 'CC'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('House', 'NNP')]), ('of', 'IN'), ('Representatives', 'NNPS'), (':', ':'), ('Among', 'IN'), ('the', 'DT'), ('vicissitudes', 'NNS'), ('incident', 'NN'), ('to', 'TO'), ('life', 'NN'), ('no', 'DT'), ('event', 'NN'), ('could', 'MD'), ('have', 'VB'), ('filled', 'VBN'), ('me', 'PRP'), ('with', 'IN'), ('greater', 'JJR'), ('anxieties', 'NNS'), ('than', 'IN'), ('that', 'DT'), ('of', 'IN'), ('which', 'WDT'), ('the', 'DT'), ('notification', 'NN'), ('was', 'VBD'), ('transmitted', 'VBN'), ('by', 'IN'), ('your', 'PRP$'), ('order', 'NN'), (',', ','), ('and', 'CC'), ('received', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('14th', 'JJ'), ('day', 'NN'), ('of', 'IN'), ('the', 'DT'), ('present', 'JJ'), ('month', 'NN'), ('.', '.')])\n"
     ]
    }
   ],
   "source": [
    "print(entities.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An n-gram is a contiguous sequence of n items from a given text or speech data. It is widely used in Natural Language Processing (NLP) to analyze patterns, predict text, and improve machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fellow', '-'),\n",
       " ('-', 'Citizens'),\n",
       " ('Citizens', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'Senate')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = list(nltk.bigrams(tokens))\n",
    "bigrams[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, to see the most frequent connections, we are prevented by stop words, so let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 20),\n",
       " ((',', 'and'), 15),\n",
       " (('to', 'the'), 11),\n",
       " (('in', 'the'), 9),\n",
       " ((',', 'I'), 7),\n",
       " ((',', 'in'), 7),\n",
       " (('which', 'the'), 6),\n",
       " (('which', 'I'), 6),\n",
       " (('by', 'the'), 6),\n",
       " (('for', 'the'), 6)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(bigrams).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave only the tokens that are not in the stopwords array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cleared = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fellow',\n",
       " 'citizens',\n",
       " 'senate',\n",
       " 'house',\n",
       " 'representatives',\n",
       " 'among',\n",
       " 'vicissitudes',\n",
       " 'incident',\n",
       " 'life',\n",
       " 'event']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_cleared[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we try to analyse a pair of 2 words - bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('fellow', 'citizens'), 3),\n",
       " (('house', 'representatives'), 2),\n",
       " (('united', 'states'), 2),\n",
       " (('good', 'assure'), 2),\n",
       " (('free', 'government'), 2),\n",
       " (('executive', 'department'), 2),\n",
       " (('american', 'people'), 2),\n",
       " (('public', 'good'), 2),\n",
       " (('citizens', 'senate'), 1),\n",
       " (('senate', 'house'), 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(nltk.bigrams(tokens_cleared)).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we try to analyse a pair of 3 words - trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('fellow', 'citizens', 'senate'), 1),\n",
       " (('citizens', 'senate', 'house'), 1),\n",
       " (('senate', 'house', 'representatives'), 1),\n",
       " (('house', 'representatives', 'among'), 1),\n",
       " (('representatives', 'among', 'vicissitudes'), 1),\n",
       " (('among', 'vicissitudes', 'incident'), 1),\n",
       " (('vicissitudes', 'incident', 'life'), 1),\n",
       " (('incident', 'life', 'event'), 1),\n",
       " (('life', 'event', 'could'), 1),\n",
       " (('event', 'could', 'filled'), 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(nltk.trigrams(tokens_cleared)).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet\n",
    "\n",
    "* Lexical database\n",
    "* Contains synsets: nouns, verbs, adjectives, adverbs\n",
    "* Connections between synsets: antonyms, hyperonyms, hyponyms, holonyms, meronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Synset is a group of synonymous words that share the same meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch all the synsets (synonym sets) of the word \"car\" from WordNet. Each synset represents a different definition of the word \"car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the first synset, which is the most common meaning of \"car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = wn.synset('car.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve all the synonyms (lemmas) for the given synset (car.n.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.lemma_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can return the definition of the selected synset (car.n.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get example sentences where this synset is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the meaning in our synonym set, we can find hyponyms (more specific words that fall under \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('minicar.n.01'),\n",
       " Synset('compact.n.03'),\n",
       " Synset('hot_rod.n.01'),\n",
       " Synset('cruiser.n.01'),\n",
       " Synset('hatchback.n.01'),\n",
       " Synset('sedan.n.01'),\n",
       " Synset('stock_car.n.01'),\n",
       " Synset('sports_car.n.01'),\n",
       " Synset('hardtop.n.01'),\n",
       " Synset('model_t.n.01'),\n",
       " Synset('cab.n.03'),\n",
       " Synset('minivan.n.01'),\n",
       " Synset('racer.n.02'),\n",
       " Synset('limousine.n.01'),\n",
       " Synset('used-car.n.01'),\n",
       " Synset('bus.n.04'),\n",
       " Synset('sport_utility.n.01'),\n",
       " Synset('horseless_carriage.n.01'),\n",
       " Synset('ambulance.n.01'),\n",
       " Synset('roadster.n.01'),\n",
       " Synset('convertible.n.01'),\n",
       " Synset('subcompact.n.01'),\n",
       " Synset('touring_car.n.01'),\n",
       " Synset('gas_guzzler.n.01'),\n",
       " Synset('coupe.n.01'),\n",
       " Synset('pace_car.n.01'),\n",
       " Synset('beach_wagon.n.01'),\n",
       " Synset('stanley_steamer.n.01'),\n",
       " Synset('jeep.n.01'),\n",
       " Synset('electric.n.01'),\n",
       " Synset('loaner.n.02')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It represents a \"parent category\" in a hierarchical relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can return part meronyms of a given synset. Meronyms represent a \"part-of\" relationship, meaning they list things that are components or parts of the whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('air_bag.n.01'),\n",
       " Synset('automobile_engine.n.01'),\n",
       " Synset('hood.n.09'),\n",
       " Synset('luggage_compartment.n.01'),\n",
       " Synset('roof.n.02'),\n",
       " Synset('gasoline_engine.n.01'),\n",
       " Synset('auto_accessory.n.01'),\n",
       " Synset('sunroof.n.01'),\n",
       " Synset('automobile_horn.n.01'),\n",
       " Synset('rear_window.n.01'),\n",
       " Synset('buffer.n.06'),\n",
       " Synset('fender.n.01'),\n",
       " Synset('glove_compartment.n.01'),\n",
       " Synset('floorboard.n.02'),\n",
       " Synset('car_window.n.01'),\n",
       " Synset('grille.n.02'),\n",
       " Synset('accelerator.n.01'),\n",
       " Synset('car_mirror.n.01'),\n",
       " Synset('first_gear.n.01'),\n",
       " Synset('stabilizer_bar.n.01'),\n",
       " Synset('bumper.n.02'),\n",
       " Synset('car_door.n.01'),\n",
       " Synset('reverse.n.02'),\n",
       " Synset('car_seat.n.01'),\n",
       " Synset('high_gear.n.01'),\n",
       " Synset('window.n.02'),\n",
       " Synset('tail_fin.n.02'),\n",
       " Synset('third_gear.n.01'),\n",
       " Synset('running_board.n.01')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('white.n.02.white')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('black')[0].lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation\n",
    "\n",
    "A text document is usually represented using a bag-of-words (BoW) model, which is a vector. The components of the vector represent individual words or n-grams from a dictionary (for the entire corpus/language). The values of the vector components can be:\n",
    "\n",
    "* count\n",
    "* frequency\n",
    "* weighted frequency\n",
    "\n",
    "Words with high frequency in a language (such as conjunctions) are referred to as *stop words* and are often removed during preprocessing.\n",
    "\n",
    "## TF-IDF\n",
    "* Term frequency * inverse document frequency\n",
    "* `TF`  frequency of a word in the current document\n",
    "* `IDF`  negative logarithm of the probability of a word occurring in a document (same for all documents)\n",
    "* Various variants (weighting schemes): https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "- A library for modeling topics in documents.\n",
    "- Implements TF-IDF, LSA, pLSA, LDA, HDP, DTM, word2vec\n",
    "- https://radimrehurek.com/gensim/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    return [token.lower() for token in tokens if token.isalpha() and token.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = [preprocess_text(text['text']) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proceeding',\n",
       " 'fellow',\n",
       " 'citizens',\n",
       " 'qualification',\n",
       " 'constitution',\n",
       " 'requires',\n",
       " 'entrance',\n",
       " 'charge',\n",
       " 'conferred',\n",
       " 'duty']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_docs[4][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing words that occur only once in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for text in tokenized_docs:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "tokenized_docs = [[token for token in doc if frequency[token] > 1] for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary from a collection of tokenized documents. Each unique word in the tokenized_docs is assigned a unique ID. The dictionary is later used for converting text into a numerical format (e.g., bag-of-words representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting tokenized text into a numerical representation using the Bag-of-Words (BoW) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_corpus = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.02865772524274559),\n",
       " (1, 0.07082134338297177),\n",
       " (2, 0.047831914834149725),\n",
       " (3, 0.014862430544438632),\n",
       " (4, 0.041811914404857924),\n",
       " (5, 0.027307199915801005),\n",
       " (6, 0.05631662889391485),\n",
       " (7, 0.06233662932320665),\n",
       " (8, 0.02560497085348817),\n",
       " (9, 0.03714243930251071)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_corpus[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models: LSI, LDA, ...\n",
    "\n",
    "We can calculate the similarity of the resulting vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(tfidf_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.05286995, 0.12033835, 0.10489108, 0.09024273,\n",
       "       0.11507139, 0.08539192, 0.14273158, 0.11627034, 0.13620742,\n",
       "       0.12669681, 0.10682183, 0.13267624, 0.16245481, 0.11774192,\n",
       "       0.12089311, 0.12477458, 0.12077793, 0.09366583, 0.0424006 ,\n",
       "       0.06105308, 0.06304477, 0.11607063, 0.0729711 , 0.10656489,\n",
       "       0.0944657 , 0.08286408, 0.09186366, 0.06875983, 0.02735389,\n",
       "       0.09153646, 0.06827688, 0.07756818, 0.0684045 , 0.0914682 ,\n",
       "       0.06663257, 0.0597512 , 0.04235245, 0.05028749, 0.03209055,\n",
       "       0.04543332, 0.07307167, 0.03767864, 0.06221583, 0.04202975,\n",
       "       0.04385568, 0.04855515, 0.03685588, 0.04443101, 0.04047035,\n",
       "       0.04416719, 0.04352387, 0.04177937, 0.04510492, 0.04515488,\n",
       "       0.0661387 , 0.04182338, 0.0243195 , 0.04833949], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[tfidf_corpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec\n",
    "\n",
    "Each word has a learned vector of real numbers that represent its various properties and capture several linguistic regularities. We can count the similarity between words as the similarity of two vectors.\n",
    "\n",
    "vector('Paris') - vector('France') + vector('Italy') ~= vector('Rome')\n",
    "\n",
    "vector('king') - vector('man') + vector('woman') ~= vector('queen')\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "https://medium.com/@mishra.thedeepak/word2vec-in-minutes-gensim-nlp-python-6940f4e00980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = brown.sents()\n",
    "model = models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('brown_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Word2Vec.load('brown_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving words that are most similar to \"mother\" based on the trained word vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('father', 0.980160653591156), ('husband', 0.9684260487556458), ('wife', 0.945469081401825), ('son', 0.9287609457969666), ('friend', 0.915546715259552), ('nickname', 0.9138074517250061), ('voice', 0.9070308804512024), ('brother', 0.8937575817108154), ('addiction', 0.885729968547821), ('patient', 0.8836824297904968)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"mother\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the word that least belongs to a given set based on word vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garden\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(\"pizza pasta garden fries\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the vector representation of the word \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.507504  ,  0.33320343,  0.5284809 ,  0.52977157, -0.5455529 ,\n",
       "       -0.48120877,  1.057019  ,  1.3028897 , -0.5378181 , -0.6858985 ,\n",
       "       -0.01705402, -0.58223695,  0.507998  , -1.0840155 ,  0.18427342,\n",
       "       -0.63021845,  0.20032336, -0.10306896, -0.7359981 , -1.0622157 ,\n",
       "        0.4540688 ,  0.1313434 ,  0.7138239 ,  0.21376345, -0.2552546 ,\n",
       "        0.08095742,  0.0123677 ,  0.02750621, -0.86284757,  0.06020001,\n",
       "        0.4214964 , -0.41749412,  1.0922868 , -0.44855723,  0.09932699,\n",
       "        0.37436983,  0.01289282, -1.0066997 , -0.24552816,  0.12656598,\n",
       "        0.19874714, -0.42525837,  0.77346265, -0.00488648,  0.622342  ,\n",
       "        0.25764716, -0.47221577, -0.16058224, -0.32392594,  0.24162896,\n",
       "        0.22696379, -0.47384137, -0.67867714, -0.39819637, -0.81504816,\n",
       "       -0.69508755,  1.2054706 , -0.10652367, -0.3895447 ,  0.23924072,\n",
       "        0.17667039,  0.24526155, -0.01167543, -0.5120434 , -0.8495882 ,\n",
       "        1.0171554 ,  0.32333955,  0.97309923, -1.1331737 ,  0.5280995 ,\n",
       "       -0.06566002,  0.14412299,  0.25298497,  0.21868016,  1.5851383 ,\n",
       "       -0.04637602,  1.1388471 ,  0.60519   , -0.6277147 , -0.5716293 ,\n",
       "       -1.0518423 ,  0.17459574, -0.7161392 ,  0.21493612, -0.5005054 ,\n",
       "       -0.08849282,  0.10654917, -0.00257797,  0.11809426,  0.09178372,\n",
       "        0.7593709 ,  0.11490364,  0.20700279, -0.13653643,  0.40396068,\n",
       "        0.24327402,  0.3054997 , -0.8548561 , -0.17475429, -0.13075897],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['human']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using scikit-learn\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting texts into the list docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [text['text'] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning the vocabulary from docs. Converting each document into a sparse matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "tf = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the sparse matrix to an array. Each index represents a word from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the list of words (features) in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '100', '108', '11', '120', '125', '13', '14th', '15th',\n",
       "       '16', '1774', '1776', '1778', '1780', '1787', '1789', '1790',\n",
       "       '1800', '1801', '1812', '1815', '1816', '1817', '1818', '1826',\n",
       "       '1850', '1861', '1863', '1868', '1873', '1880', '1886', '1890',\n",
       "       '1893', '1896', '1897', '1898', '1899', '18th', '1907', '1917',\n",
       "       '1933', '1941', '1945', '1963', '1972', '1980', '1984', '19th',\n",
       "       '20', '200', '200th', '2017', '20th', '21st', '225', '25', '30',\n",
       "       '30th', '3d', '40', '400', '41', '48', '4th', '50', '50th', '60',\n",
       "       '67', '6th', 'abandon', 'abandoned', 'abandonment', 'abate',\n",
       "       'abdicated', 'abeyance', 'abhorring', 'abide', 'abiding',\n",
       "       'abilities', 'ability', 'abject', 'able', 'ably', 'abnormal',\n",
       "       'abode', 'abodes', 'abolish', 'abolished', 'abolishing',\n",
       "       'aboriginal', 'aborigines', 'abound', 'abounding', 'abounds',\n",
       "       'abraham', 'abreast', 'abridging', 'abroad', 'absence'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting text data into a numerical format using the TF-IDF (Term Frequency-Inverse Document Frequency) representation. This is an improvement over the Bag-of-Words (BoW) model, as it assigns importance weights to words instead of just counting occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = transformer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05754421, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()[0][:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
