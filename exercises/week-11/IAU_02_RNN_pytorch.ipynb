{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc5c1f-aa7c-40b1-8f05-a56b5f5cda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec5afd-e031-4cbf-a708-5ec03792a853",
   "metadata": {},
   "source": [
    "# Time-series forecasting with Deep Learning (PyTorch)\n",
    "\n",
    "### Author: Matej Voľanský alias DC Wenders (2024)\n",
    "\n",
    "Inspired by https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-11/IAU_113_RNN-tf-keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18885430-e93e-475a-ae77-2e4adf050f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(context='paper', style='whitegrid', color_codes=True)   \n",
    "sns.set_palette(sns.color_palette([\"#017b92\", \"#f97306\", \"#ff0000\"]))  # [\"green\", \"orange\", \"red\"] \n",
    "\n",
    "def decide_device():\n",
    "  if (torch.cuda.is_available()): return \"cuda\"\n",
    "  #if (torch.backends.mps.is_available()): return \"mps\"\n",
    "  return \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578d386-0e5d-4623-bce6-c0f8c1fc8cf6",
   "metadata": {},
   "source": [
    "## Data creation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0530a6d-bb35-4d3b-8308-ad135e16eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "x = np.arange(0, n, 1) \n",
    "y = np.sin(16*np.pi*x/n) + np.cos(32*np.pi*x/n) + np.random.rand(n)\n",
    "data_org = y.reshape(-1, 1)\n",
    "\n",
    "print(data_org.shape)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,2)\n",
    "plt.plot(data_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe1da2-d726-41c0-bef8-8c0dd286fd37",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f80ce-fbaf-4817-afc7-f1a80ecfd609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity test\n",
    "dftest = adfuller(data_org, autolag='AIC')\n",
    "print(f\"\\t1. ADF: {dftest[0]}\")\n",
    "print(f\"\\t2. P-Value: {dftest[1]}\")\n",
    "print(f\"\\t3. Num Of Lags: {dftest[2]}\")\n",
    "\n",
    "# Seasonal decomposition\n",
    "result = STL(data_org, period=6, robust=True).fit()\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "data_cleaned = result.trend.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f90455-b0ef-40f7-a8b6-1c290e80a67f",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0291a3a-3fe7-4bde-b62a-77122c0b0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_trans = scaler.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e363c5-b508-4394-88ee-02610b7338f6",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7f757-6f51-4af3-bb73-5770e9a8b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data_trans) * 0.80)\n",
    "test_size = len(data_trans) - train_size\n",
    "train, test = data_trans[0:train_size, :], data_trans[train_size:len(data_trans), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85621a4-0fb0-4cb6-ac7f-700bce3c197c",
   "metadata": {},
   "source": [
    "## PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba532ae3-3a8d-44d4-acd8-6a53693a85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "\n",
    "def create_dataset(data, look_back):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(data) - look_back):\n",
    "        sequence = data[i:i + look_back]\n",
    "        target = data[i + look_back]\n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "\n",
    "    sequences, targets = np.array(sequences), np.array(targets)\n",
    "    return torch.tensor(sequences).float(), torch.tensor(targets).float()\n",
    "\n",
    "train_sequences, train_targets = create_dataset(train, look_back)\n",
    "test_sequences, test_targets = create_dataset(test, look_back)\n",
    "\n",
    "train_dataset = TensorDataset(train_sequences, train_targets)\n",
    "test_dataset = TensorDataset(test_sequences, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9544d3-0aac-467e-93aa-8a2efc42d9d8",
   "metadata": {},
   "source": [
    "## PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecc640-902e-4c7b-b055-e88ddfa321a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        x = self.linear(h_n.squeeze(0))\n",
    "        return x\n",
    "\n",
    "model = LSTMModel(1, 5, 1)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device(decide_device())\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cae06-21fc-40a1-b417-9fd4b0ce4ae5",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9ed60-b1f5-481a-a4ae-a5d8452a7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    global best_model_state\n",
    "    model.train()\n",
    "    curr_loss = 200\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        for sequences, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if loss.item() < curr_loss:\n",
    "            print(\"Found best model at epoch: \",epoch)\n",
    "            curr_loss = loss.item()\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            \n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "train(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88175ee8-b48c-4efc-a260-1233cfb6f5df",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2de698-efc3-4ffc-8c2c-50957063ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in loader:\n",
    "            outputs = model(sequences)\n",
    "            predictions.append(outputs.numpy())\n",
    "            actuals.append(targets.numpy())\n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "trainPredict, trainY = evaluate(model, train_loader)\n",
    "testPredict, testY = evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839948e7-2e61-413f-9055-4c710d7f0042",
   "metadata": {},
   "source": [
    "## Rescaling predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e47e73-c1e2-42ba-92bf-6a8de9d6c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform(trainPredict.reshape(-1, 1))\n",
    "testPredict = scaler.inverse_transform(testPredict.reshape(-1, 1))\n",
    "trainY = scaler.inverse_transform(trainY.reshape(-1, 1))\n",
    "testY = scaler.inverse_transform(testY.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42f824-0d3f-4722-9c1b-cc324ea8e932",
   "metadata": {},
   "source": [
    "## Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74b945-56f2-4d4a-a16e-0f0159bf497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "torch.save(best_model_state, 'lstm_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f19734-2207-4a92-b2e5-9e4c35272f14",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c630b-7e3d-43cc-a024-e9c30a01a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = train_size + look_back\n",
    "end = begin + len(testPredict)\n",
    "\n",
    "testYPlot = np.empty_like(data_org)\n",
    "testYPlot[:, :] = np.nan\n",
    "testYPlot[begin:end, :] = testY\n",
    "\n",
    "testPredictPlot = np.empty_like(data_org)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[begin:end, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.rcParams[\"figure.figsize\"] = (12,3)\n",
    "plt.plot(data_org)\n",
    "plt.plot(testYPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
