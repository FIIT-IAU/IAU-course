## Optimization (hyper-parameter tuning) for Deep Learning

### Weights & Biases (WandB)
- [Using Weights & Biases (WandB) for Log Training](https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-11/IAU_wandb_README.md)
- [WandB for Musiker e-shop](https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-11/IAU_01_LSTM-sale-trend-prediction-wandb.ipynb)
  
### Hyper-parameter tuning for deep learning models
[Keras tunner](https://keras.io/guides/keras_tuner/): currently supports four tuners: Hyperband, Bayesian Optimization, RandomSearch, and Sklearn
- [Example: keras tuner for deep learning](https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-11/IAU_02-keras-tuner-for-deep-learning.ipynb)

[Optuna](https://optuna.org/)
- [Example: optuna tuning for pytorch](https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-11/IAU_03-optuna-tuning-for-pytorch.ipynb)

### Bayesian Optimization for ML hyperparameter tuning
[Bayesian Optimization for ML](https://scikit-optimize.github.io)
- [Example: bayesian optimization for ML](https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-12/IAU_homework_bayesian-optimization-for-machine-learning.ipynb)
- [Understanding Bayesian Optimization](https://github.com/FIIT-IAU/IAU-course/blob/main/exercises/week-12/IAU_homework_Understanding-Bayesian-optimization.ipynb)

## Foundation of Generative AI and Deep Learning 
- https://github.com/FIIT-ISA/ISA-course
